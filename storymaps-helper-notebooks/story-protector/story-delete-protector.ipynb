{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Story protector\n",
    "This notebook crawls the items, maps, dashboards, scenes, within a story and delete protects those items and their content provided it is within your org.\n",
    "\n",
    "## How to run\n",
    "1. Provide the `itemId` of your story to the `story_id` parameter below.\n",
    "2. Configure `delete_protect` to set whether you would like to apply **delete protection** to the story and all of the content items found within it. **True** = protect items, **False** = leave unprotected.\n",
    "3. Configure `share` to set whether you would like to perform a bulk update of the sharing permissions for the story and all of its content.\n",
    "4. If `share` is set to **True**, provide a sharing level 'private', 'org', or 'public'\n",
    "5. Once parameters have been configured, click 'Cell' > 'Run All' in the menu bar above.\n",
    "6. Scroll down in the notebook and inspect the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## These are the input parameters\n",
    "story_id = '' # <-- Paste your story itemId here\n",
    "delete_protect = True # <- toggle the delete protection ON (True) or OFF (False)\n",
    "## If the `share` setting below is False then this setting won't be configured and the `share_level` will also be ignored.\n",
    "share = False # <- if you want to bulk share the content set this to True otherwise, False\n",
    "share_level = 'public' # <- set this to ['private', 'org', or 'public']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script setup\n",
    "These are functions that do smaller tasks within the main script. For instance, some crawl specific items like dashboards or webmaps and other crawl nested group layers within a webmap.\n",
    "\n",
    "Storing them here is just easier and makes bits of code re-usable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.gis import GIS\n",
    "from arcgis.gis import Item\n",
    "from arcgis.mapping import WebMap, WebScene\n",
    "from arcgis.apps.expbuilder.expbuilder import WebExperience\n",
    "import re # import regex\n",
    "import pandas as pd\n",
    "\n",
    "# Set Pandas dataframe display options\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns',500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define embed types to look for\n",
    "embedTypes = ['dashboards', 'survey123', 'experience'] ## <- More here?\n",
    "\n",
    "# Empty container to eventually hold all of the items found within the story\n",
    "itemList = []\n",
    "\n",
    "# This class will allow for building a graph later\n",
    "# Define a relation class to store all the found relationships\n",
    "class Relation:\n",
    "    _relations_list = []\n",
    "    item = ''\n",
    "    resource = ''\n",
    "\n",
    "    def __init__(self, itemId, resourceId):\n",
    "        self._relations_list.append(self)\n",
    "        self.item = itemId\n",
    "        self.resource = resourceId\n",
    "\n",
    "# Define a crawler helper to fetch the item info\n",
    "def getResourceInfo(resourceId, itemList):\n",
    "    query = f\"id: {resourceId}\"\n",
    "    resource = gis.content.advanced_search(query=query, max_items=-1, as_dict=True)['results']\n",
    "    if len(resource) > 0:\n",
    "        itemList += resource\n",
    "\n",
    "\n",
    "# Crawl story nodes for embeds of ArcGIS Apps\n",
    "def crawl_story_embeds(story_json, found_data, itemList):\n",
    "    if story_json.get('nodes') is not None and found_data:\n",
    "        for resource, value in story_json['nodes'].items():\n",
    "            if value['type'] == 'embed' and 'url' in value['data'].keys():# and value['data']['title'] in embedTypes:\n",
    "                if re.search(r'[\\/]dashboards[\\/]|\\/experience[.]|\\/survey123[.]',value['data']['url'],re.IGNORECASE):\n",
    "                    embedApp = str(re.search(r'[\\/]dashboards[\\/]|\\/experience[.]|\\/survey123[.]',value['data']['url'],re.IGNORECASE).group())[1:-1]\n",
    "                    if embedApp == 'dashboards':\n",
    "                        embedUrl = value['data']['url']\n",
    "                        resourceId = embedUrl.split('/')[-1]\n",
    "                        getResourceInfo(resourceId, itemList)\n",
    "                        Relation(story_id, resourceId) ###### <-\n",
    "                        crawl_dashboard(gis, resourceId, itemList)\n",
    "                    elif embedApp == 'experience':\n",
    "                        embedUrl = value['data']['url']\n",
    "                        resourceId = embedUrl.split('/')[-1]\n",
    "                        getResourceInfo(resourceId, itemList)\n",
    "                        Relation(story_id, resourceId) ###### <-\n",
    "                        crawl_experience(resourceId, itemList)\n",
    "                    elif embedApp == 'survey123':\n",
    "                        embedUrl = re.search(r'\\&id=(.*?)\\&', value['data']['url'], re.IGNORECASE)\n",
    "                        resourceId = embedUrl.group(1)\n",
    "                        getResourceInfo(resourceId, itemList)\n",
    "                        Relation(story_id, resourceId) ###### <-\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "        \n",
    "# Crawl story resources for webmaps and other resources                 \n",
    "def crawl_story_resources(story_json, found_data, itemList): \n",
    "    if story_json.get('resources') is not None and found_data:\n",
    "        for resource, value in story_json['resources'].items():\n",
    "            if value['type'] == 'webmap' or value['type'] == 'webscene':\n",
    "                resourceId = value['data']['itemId']\n",
    "                getResourceInfo(resourceId, itemList)\n",
    "                Relation(story_id, resourceId) ###### <-\n",
    "                crawl_webmap(resourceId, itemList)\n",
    "\n",
    "\n",
    "            # Check for story theme\n",
    "            elif value['type'] == 'story-theme':\n",
    "                if 'themeItemId' in value['data']:\n",
    "                    resourceId = value['data']['themeItemId']\n",
    "                    getResourceInfo(resourceId, itemList)\n",
    "                    Relation(story_id, resourceId) ###### <-\n",
    "        \n",
    "        \n",
    "# ArcGIS Dashboards\n",
    "def crawl_dashboard(gis, itemId, itemList):\n",
    "    dashboard = Item(gis = gis, itemid = itemId)\n",
    "    found_data = False\n",
    "    # check for dashboardData\n",
    "    try:\n",
    "        dashboard_json = dashboard.get_data()\n",
    "        found_data = True\n",
    "    except:\n",
    "        print('could not find data')\n",
    "    # Crawl dashboard for views and widget datasets within\n",
    "    if dashboard_json is not None and found_data:\n",
    "        if 'desktopView' in dashboard_json.keys():\n",
    "            for widget in dashboard_json['desktopView']['widgets']:\n",
    "                # if widget has a direct itemId\n",
    "                if 'itemId' in widget:\n",
    "                    resourceId = widget['itemId']\n",
    "                    getResourceInfo(resourceId, itemList)\n",
    "                    Relation(itemId, resourceId) ###### <-\n",
    "                    if 'type' in widget and widget['type'] == 'mapWidget':\n",
    "                        crawl_webmap(resourceId, itemList)\n",
    "                        \n",
    "                # elif widget is based on a dataset\n",
    "                elif 'datasets' in widget and 'dataSource' in widget['datasets']:\n",
    "                    for dataset in widget['datasets']:\n",
    "                        if 'itemId' in dataset['dataSource']:\n",
    "                            resourceId = dataset['dataSource']['itemId']\n",
    "                            getResourceInfo(resourceId, itemList)\n",
    "                            Relation(itemId, resourceId) ###### <-\n",
    "        elif 'widgets' in dashboard_json.keys():\n",
    "            for widget in dashboard_json['widgets']:    \n",
    "                # if widget has a direct itemId\n",
    "                if 'itemId' in widget:\n",
    "                    resourceId = widget['itemId']\n",
    "                    getResourceInfo(resourceId, itemList)\n",
    "                    Relation(itemId, resourceId) ###### <-\n",
    "                # elif widget is based on a dataset\n",
    "                elif 'datasets' in widget and 'dataSource' in widget['datasets']:\n",
    "                    for dataset in widget['datasets']:\n",
    "                        if 'itemId' in dataset['dataSource']:\n",
    "                            resourceId = dataset['dataSource']['itemId']\n",
    "                            getResourceInfo(resourceId, itemList)\n",
    "                            Relation(itemId, resourceId) ###### <-\n",
    "        \n",
    "\n",
    "# ArcGIS Web Experiences\n",
    "def crawl_experience(itemId, itemList):\n",
    "    experience = WebExperience(item=itemId)\n",
    "    # Return datasource dictionary\n",
    "    sources = experience.datasources\n",
    "    # if dictionary is present crawl datasources\n",
    "    if sources:\n",
    "        for s in sources.keys():\n",
    "            resourceId = sources[s]['itemId']\n",
    "            getResourceInfo(resourceId, itemList)\n",
    "            if sources[s]['type'] == 'WEB_SCENE':\n",
    "                crawl_webmap(resourceId, itemList)\n",
    "            elif sources[s]['type'] == 'WEB_MAP':\n",
    "                crawl_webmap(resourceId, itemList)\n",
    "            \n",
    "# Crawl group layers within a WebMap                              \n",
    "def crawl_group(mapId, group, itemList):\n",
    "    for l in group['layers']:\n",
    "        # if group layer\n",
    "        if l['layerType'] == 'GroupLayer':\n",
    "            crawl_group(mapId, l, itemList)\n",
    "        # if feature layer\n",
    "        else:\n",
    "            if 'itemId' in l:\n",
    "                resourceId = l['itemId']\n",
    "                getResourceInfo(resourceId, itemList)\n",
    "                Relation(mapId, resourceId) ###### <-\n",
    "\n",
    "                \n",
    "# ArcGIS Online WebMaps/WebScenes\n",
    "# Turns out Scenes and Map have the same data model so we can crawl both with the same function\n",
    "def crawl_webmap(itemId, itemList):\n",
    "    map = gis.content.get(itemId)\n",
    "    map_data = map.get_data()\n",
    "    \n",
    "    for layer in map_data['operationalLayers']:\n",
    "        if layer['layerType'] == 'GroupLayer':\n",
    "            crawl_group(itemId, layer, itemList)\n",
    "        else:\n",
    "            if 'itemId' in layer:\n",
    "                resourceId = layer['itemId']\n",
    "                getResourceInfo(resourceId, itemList)\n",
    "                Relation(itemId, resourceId) ###### <-\n",
    "            # can't do much if I don't have the itemId\n",
    "    \n",
    "    for layer in map_data['baseMap']['baseMapLayers']:\n",
    "        if layer['layerType'] == 'GroupLayer':\n",
    "            crawl_group(itemId, layer, itemList)\n",
    "        else:\n",
    "            resourceId = layer['itemId']\n",
    "            getResourceInfo(resourceId, itemList)\n",
    "            Relation(itemId, resourceId) ###### <-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content discovery\n",
    "The script below crawls the story data and calls the helper functions defined above to subsequently crawl the contents of items found within the story.\n",
    "\n",
    "Once this block runs the script will return a table showing all the items found within the story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GIS\n",
    "gis = GIS(\"home\")\n",
    "\n",
    "# Define the main story crawler function\n",
    "# Crawl the story to find items and record their item_id\n",
    "story = Item(gis, story_id)\n",
    "getResourceInfo(story_id, itemList)\n",
    "# Check for storyData\n",
    "found_data = False\n",
    "try:\n",
    "    story_json = story.nodes.get('published_data.json', try_json=True)\n",
    "    found_data = True\n",
    "except:\n",
    "    # old story saved to item_data\n",
    "    try:\n",
    "        story_json = story.get_data()\n",
    "        found_data = True\n",
    "    except:\n",
    "        print('could not find data')\n",
    "\n",
    "\n",
    "# Crawl contents\n",
    "crawl_story_embeds(story_json, found_data, itemList)\n",
    "crawl_story_resources(story_json, found_data, itemList)\n",
    "\n",
    "# Turn the contents from the story into a dataframe\n",
    "items_df = pd.DataFrame(itemList)\n",
    "# Create a convenient subset of columns\n",
    "items_df = items_df[['id', 'owner', 'created', 'isOrgItem', 'modified', 'title', 'type','protected', 'access']] # drop columns except these\n",
    "# Remove duplicate items\n",
    "items_df = items_df.drop_duplicates(subset='id') # drop duplicate items\n",
    "# Filter to only show those items that are within the 'home' org\n",
    "items_df = items_df.loc[items_df['isOrgItem'] == True]\n",
    "\n",
    "# Preview\n",
    "items_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Protect the items\n",
    "Using the table of items above, this next block will loop through those items and perform to desired protection and sharing updates.\n",
    "\n",
    "Once complete, this block will report back an updated table of all the items for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Now that we have a list of items we'll protect them from deletion and optionally make them public\n",
    "id_list = items_df['id'].tolist()\n",
    "\n",
    "# Function to perform the protection and sharing\n",
    "def update_item_properties(item, protection, share, level):\n",
    "    i = gis.content.get(item)\n",
    "    i.protect(enable = protection)\n",
    "    if share:\n",
    "        i.update(item_properties={\"access\": level})\n",
    "\n",
    "# Update the settings for each item\n",
    "for item in id_list:\n",
    "    try:\n",
    "        update_item_properties(item, delete_protect, share, share_level)\n",
    "    except:\n",
    "        print('Error: Could not update \"{0}\".'.format(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Review the results\n",
    "Wait a few moments after running the above. This last cell will query those items that were protected and present an updated table where you can confirm that things were protected/shared as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Reset the container\n",
    "itemList = []\n",
    "\n",
    "# Re-query the items to refresh the properties\n",
    "for item in id_list:\n",
    "    getResourceInfo(item, itemList)\n",
    "\n",
    "# Turn the contents from the story into a dataframe\n",
    "items_df = pd.DataFrame(itemList)\n",
    "# Create a convenient subset of columns\n",
    "items_df = items_df[['id', 'owner', 'created', 'isOrgItem', 'modified', 'title', 'type','protected', 'access']] # drop columns except these\n",
    "items_df"
   ]
  }
 ],
 "metadata": {
  "esriNotebookRuntime": {
   "notebookRuntimeName": "ArcGIS Notebook Python 3 Standard",
   "notebookRuntimeVersion": "9.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
